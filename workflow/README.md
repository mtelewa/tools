# Description:

Initialization, Equilibration and Non-equilibrium MD simulation on pentane with gold walls.

# Workflow:

1. **Initialize**: Run the python module _init\_Moltemp\_walls_ (located in `home/tools`) in `equilib/data/moltemp` with the positional arguments. Usage:\
`init_moltemp_walls.py nUnitsX nUnitsY nUnitsZ h density fluid` \
The main variables here are `nUnitsX` and `density`\
This will create _geometry.lt_ file with the system dimensions and topology.

2. Run the `setup.sh` bash script. The initial atomic configuration is now created with all the simulation settings. \
Inside the _setup_ bash script, the command used is \
`moltemplate.sh -atomstyle full -overlay-bonds -overlay-angles -overlay-dihedrals -overlay-impropers system.lt` \
The `-overlay-*` flags are required for cases where multiple bonded interactions involve the same atoms.
This will create:
    * _system.in.init_ &rarr; Generated either by the force field file or the molecule geometry file and it comprises the initialization setup  
    * _system.in.settings_ &rarr; Generated either by the force field file or the molecule geometry file and it comprises the force field parameters  
    * _system.in.run_ &rarr; Generated by _system.lt_ from what was specified in the python file and it contains the simulation conditions (NVT,NVE,etc)  
    * _system.in.output_ &rarr; Generated by _system.lt_ from what was specified in the python file and it contains info on the thermodynamic output and its frequency.
    * _system.data_; LAMMPS data file.

    The _setup_ script will also modify the simulation header file and will copy all the simulation files into `equilib\data\blocks`. The input files for equilibration are now ready and the `equilib` directory is to be rsynced to the cluster **NEMO**.

3. **Equilibrate**: The equilibration is performed by submitting as a batch job in the `equilib/data`.\
`msub submit_parallel.moab` \
In this script, we run LAMMPS in parallel with the command\
`mpirun --bind-to core --map-by core -report-bindings lmp_mpi -in $(pwd)/equilib.LAMMPS -v get_virial 1 ` \
The variable `get_virial` can be set to 1 or 0, depending on whether a calculation of the virial pressure is needed.

4. **Load**: The output LAMMPS data file _data.nvt_ (if the `get_virial` was 0) or _data.virial_ (if it was 1) from the equilibration step `equilib/data/out` is copied to the input of the loading `load/data/blocks`. \
(Note if _data.virial_ is used it has to be renamed to _data.nvt_ since the _load.LAMMPS_ file only accepts this name). \
The main new file (from the equilibration step) in the `load/data/blocks` directory is the `system.in.loadUpper` which loads the upper wall. \
The main variable here is the `Pext` in the _header.LAMMPS_ file in the blocks.
And again the `get_virial` variable as in the equilibration. \
A batch job can now be submitted to the cluster. The main content of the submission script is\
`mpirun --bind-to core --map-by core -report-bindings lmp_mpi -in $(pwd)/load.LAMMPS -v get_virial 1 -v Pext 100`

5. **Flow**: Now the final part in the MD calculation is to induce a flow on the atoms/molecules. This is performed either by simulating a pressure gradient or shearing.\
As for pressure gradient, we have the **Norton ensemble** where we impose a fixed force field on a group of atoms or the **Thevenin ensemble** where we impose a fixed center of mass velocity (or mass flux) field instead. The two ensembles are physically equivalent and they result in a Poiseuille flow.
For shearing the upper wall, fluid atoms flow due to the velocity gradient and we get a Couette flow.\
And indeed we want also want to simulate a Couette + Poiseuille flow.
    * Now we need to apply the flow on the already loaded structure data file _data.force_ or _data.virial_. (and the same applies as before about changing the name of the file if it is the latter). In addition to that we also need to account that the center of mass of the simulation box now changed due to loading. For that the _comZ.txt_ file is printed during the MD simulation and it contians the timeseries of the COM in the z-direction (loading direction). Also the height timeseries stored in _h.txt_ need to be copied to the flow directory. These 2 files together are needed to modify the new header file of the flow simulation. To clarify, first we have:
    `cp load/data/out/{data.force,h.txt,comZ.txt} flow/data/blocks` \
    Inside `flow/data/blocks`, we do\
    `get_com.py <skip>`\
    where `skip` is a positional argument for how many timesteps we need to discard to compute the new average height (after loading). This new height will be used to define our regions and groups according to LAMMPS syntax. For example we will use it to define our new fluid region after loading. The python module is located in `tools/` and it outputs a new header file for the flow simulation, with the right parameters.
    * Since this is the main part of the parametric study, we can change many parameters: the applied pressure difference `pDiff`, whether it is a Norton or Thevenin ensemble `norton 1` or `thevenin 1`. (Note that `norton 0` will not do a Thevenin simulation and vice versa). If we simulate shearing then `couette 1`, in this case we need to specify a `vshear` variable. \
    An example of the command in the submission script is\
    `mpirun --bind-to core --map-by core -report-bindings lmp_mpi -in $(pwd)/flow.LAMMPS -v norton 1 -v pDiff 5e6`

**Post Processing**: The trajectories file format is based on the NetCDF (Network Common Data Form) developed by [Unidata](http://www.unidata.ucar.edu/software/netcdf/). The **NetCDF** trajectories can be analysed at any stage of the simulation process by [netCDF4](https://unidata.github.io/netcdf4-python/) which is a Python interface to the netCDF C library. This is still under development...
